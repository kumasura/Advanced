{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": []}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "code", "source": ["!pip install torch_geometric torch_geometric_temporal"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "5Iun3LhkkS45", "outputId": "cb9bd58d-e9ab-4968-fd66-d5dc285bc113"}, "execution_count": null, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Collecting torch_geometric\n", "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n", "\u001b[?25l     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n", "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n", "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n", "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n", "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n", "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n", "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n", "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n", "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n", "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n", "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n", "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n", "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n", "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n", "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n", "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n", "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n", "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n", "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n", "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n", "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25hInstalling collected packages: torch_geometric\n", "Successfully installed torch_geometric-2.6.1\n"]}]}, {"cell_type": "code", "source": ["# METRLA dataset loader using torch_geometric_temporal\n", "from torch_geometric_temporal.dataset import METRLADatasetLoader\n", "from torch_geometric.data import TemporalData\n", "\n", "def load_metrla_temporal_data():\n", "    loader = METRLADatasetLoader()\n", "    dataset = loader.get_dataset(num_timesteps_in=1, num_timesteps_out=1)\n", "    snapshot = next(iter(dataset))\n", "    edge_index = snapshot.edge_index.clone().detach().long()\n", "    src = edge_index[0]\n", "    dst = edge_index[1]\n", "    t = torch.zeros(src.size(0))\n", "    if hasattr(snapshot, 'edge_weight') and snapshot.edge_weight is not None:\n", "        msg = snapshot.edge_weight.clone().detach().float().view(-1, 1)\n", "    elif hasattr(snapshot, 'edge_attr') and snapshot.edge_attr is not None:\n", "        msg = snapshot.edge_attr.clone().detach().float()\n", "        if msg.dim() == 1:\n", "            msg = msg.view(-1, 1)\n", "    else:\n", "        msg = torch.ones(src.size(0), 1, dtype=torch.float32)\n", "    data = TemporalData(src=src, dst=dst, t=t, msg=msg)\n", "    num_nodes = snapshot.x.shape[0]\n", "    return data, num_nodes\n"], "metadata": {"id": "metrla_loader"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "gRPPHkPii1GG"}, "outputs": [], "source": ["# HTGN++: Hierarchical Temporal Graph Network with Bayesian Embeddings and Learnable Time Kernels\n", "# Dataset: general TemporalData input (e.g., METRLA)\n", "\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.manifold import TSNE\n", "from torch_geometric.data import TemporalData, DataLoader\n", "\n", "# === Learnable Temporal Encoding ===\n", "class TemporalEncoding(nn.Module):\n", "    def __init__(self, num_kernels=8):\n", "        super().__init__()\n", "        self.freqs = nn.Parameter(torch.randn(num_kernels))\n", "        self.weights = nn.Parameter(torch.randn(num_kernels))\n", "\n", "    def forward(self, delta_t):\n", "        delta_t = delta_t.unsqueeze(-1)\n", "        return (self.weights * torch.sin(self.freqs * delta_t)).sum(-1)\n", "\n", "# === HTGN++ Model with PyG Integration ===\n", "class HTGN(nn.Module):\n", "    def __init__(self, num_nodes, node_dim=32, msg_dim=64, embed_dim=16):\n", "        super().__init__()\n", "        self.memory_short = nn.Parameter(torch.zeros(num_nodes, node_dim))\n", "        self.memory_long = nn.Parameter(torch.zeros(num_nodes, node_dim))\n", "\n", "        self.temporal_enc = TemporalEncoding()\n", "        self.msg_net = nn.Sequential(\n", "            nn.Linear(4 + 1, msg_dim), nn.ReLU(), nn.Linear(msg_dim, node_dim)\n", "        )\n", "        self.update_gru = nn.GRUCell(node_dim, node_dim)\n", "\n", "        self.mu_net = nn.Linear(node_dim * 2, embed_dim)\n", "        self.logvar_net = nn.Linear(node_dim * 2, embed_dim)\n", "        self.pred_net = nn.Sequential(nn.Linear(embed_dim * 2, 32), nn.ReLU(), nn.Linear(32, 1))\n", "\n", "    def forward(self, data):\n", "        losses, mus, logvars = [], [], []\n", "        for i in range(data.t.size(0)):\n", "            t = data.t[i].unsqueeze(0)\n", "            src, tgt = data.src[i], data.dst[i]\n", "            feat = data.msg[i]\n", "\n", "            time_embed = self.temporal_enc(t)\n", "            msg = self.msg_net(torch.cat([feat, time_embed]))\n", "            with torch.no_grad():\n", "              self.memory_short[src] = self.update_gru(msg.unsqueeze(0), self.memory_short[src].unsqueeze(0)).squeeze(0)\n", "              self.memory_long[src] = 0.99 * self.memory_long[src] + 0.01 * self.memory_short[src]\n", "\n", "            m_src = torch.cat([self.memory_short[src], self.memory_long[src]])\n", "            mu = self.mu_net(m_src)\n", "            logvar = self.logvar_net(m_src)\n", "            std = torch.exp(0.5 * logvar)\n", "            eps = torch.randn_like(std)\n", "            z_src = mu + eps * std\n", "\n", "            m_tgt = torch.cat([self.memory_short[tgt], self.memory_long[tgt]])\n", "            mu_tgt = self.mu_net(m_tgt)\n", "            logvar_tgt = self.logvar_net(m_tgt)\n", "            std_tgt = torch.exp(0.5 * logvar_tgt)\n", "            eps_tgt = torch.randn_like(std_tgt)\n", "            z_tgt = mu_tgt + eps_tgt * std_tgt\n", "\n", "            pred = self.pred_net(torch.cat([z_src, z_tgt]))\n", "            label = torch.tensor([1.0])  # or real label if available\n", "\n", "            loss_recon = F.binary_cross_entropy_with_logits(pred, label)\n", "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n", "            loss = loss_recon + 1e-3 * kl_loss\n", "\n", "            losses.append(loss)\n", "            mus.append(mu.detach().numpy())\n", "            logvars.append(logvar.detach().numpy())\n", "\n", "        return torch.stack(losses).mean(), np.array(mus), np.array(logvars)\n", "\n", "# === Training Setup ===\n", "def train_htgn(data, num_nodes):\n", "    model = HTGN(num_nodes)\n", "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n", "    losses = []\n", "    for epoch in range(10):\n", "        loss, mus, logvars = model(data)\n", "        loss.backward()\n", "        optimizer.step()\n", "        optimizer.zero_grad()\n", "        losses.append(loss.item())\n", "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n", "\n", "    # Visualization\n", "    plt.plot(losses)\n", "    plt.title(\"Training Loss\")\n", "    plt.xlabel(\"Epoch\")\n", "    plt.ylabel(\"Loss\")\n", "    plt.show()\n", "\n", "    tsne = TSNE(n_components=2)\n", "    embeddings_2d = tsne.fit_transform(mus)\n", "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.6)\n", "    plt.title(\"t-SNE of Node Embeddings\")\n", "    plt.show()\n", "\n", "    plt.hist(np.exp(logvars).flatten(), bins=30)\n", "    plt.title(\"Bayesian Embedding Variance\")\n", "    plt.xlabel(\"Variance\")\n", "    plt.ylabel(\"Count\")\n", "    plt.show()\n", "\n", "\n"]}, {"cell_type": "code", "source": ["# TGN baseline model for temporal link prediction\n", "\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import roc_auc_score, f1_score, roc_curve\n", "from torch_geometric.nn import TGNMemory\n", "from torch_geometric.data import TemporalData\n", "from torch_geometric.nn.models.tgn import LastAggregator\n", "from torch_geometric.utils import scatter_argmax\n", "\n", "# === Message Module Wrapper with correct TGNMemory input signature ===\n", "class MessageNet(nn.Module):\n", "    def __init__(self, input_dim, output_dim):\n", "        super().__init__()\n", "        self.net = nn.Sequential(\n", "            nn.Linear(input_dim, output_dim),\n", "            nn.ReLU(),\n", "            nn.Linear(output_dim, output_dim)\n", "        )\n", "        self.out_channels = output_dim\n", "\n", "    def forward(self, src, dst, t, raw_msg):\n", "        if raw_msg.size(0) == 0:\n", "            return raw_msg.new_zeros((0, self.out_channels))\n", "\n", "        # Sanitize time encoding shape\n", "        if t.dim() == 1:\n", "            t = t.unsqueeze(-1)\n", "        elif t.dim() == 2 and t.size(1) != 1:\n", "            t = t.mean(dim=1, keepdim=True)  # reduce if too wide\n", "\n", "        # Truncate or expand to match raw_msg batch size\n", "        t = t[:raw_msg.size(0)]\n", "\n", "        if t.size(0) != raw_msg.size(0):\n", "            pad_size = raw_msg.size(0) - t.size(0)\n", "            t = torch.cat([t, t.new_zeros(pad_size, 1)], dim=0)\n", "\n", "        x = torch.cat([raw_msg, t], dim=-1)\n", "        return self.net(x)\n", "\n", "# === TGN Model ===\n", "\nclass SafeLastAggregator(nn.Module):\n", "    def forward(self, msg, index, t, dim_size):\n", "        argmax = scatter_argmax(t, index, dim=0, dim_size=dim_size)\n", "        out = msg.new_zeros((dim_size, msg.size(-1)))\n", "        mask = argmax < msg.size(0)\n", "        out[mask] = msg[argmax[mask]]\n", "        return out\n", "\n", "class TGNLinkPredictor(nn.Module):\n", "    def __init__(self, num_nodes, msg_dim, emb_dim=32):\n", "        super().__init__()\n", "        self.memory = TGNMemory(\n", "            num_nodes=num_nodes,\n", "            raw_msg_dim=msg_dim,\n", "            memory_dim=emb_dim,\n", "            time_dim=1,\n", "            message_module=MessageNet(msg_dim + 1, emb_dim),\n", "            aggregator_module=SafeLastAggregator())\n", "\n", "        self.edge_predictor = nn.Sequential(\n", "            nn.Linear(2 * emb_dim, emb_dim),\n", "            nn.ReLU(),\n", "            nn.Linear(emb_dim, 1)\n", "        )\n", "\n", "    def forward(self, src, dst):\n", "        z_src = self.memory.memory[src]\n", "        z_dst = self.memory.memory[dst]\n", "        return self.edge_predictor(torch.cat([z_src, z_dst], dim=-1))\n", "\n", "    def update_memory(self, src, dst, t, msg):\n", "        self.memory.update_state(src, dst, t, msg)\n", "\n", "# === Training and Evaluation ===\n", "def train_tgn(data, num_nodes, epochs=10):\n", "    model = TGNLinkPredictor(num_nodes=num_nodes, msg_dim=data.msg.size(-1))\n", "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n", "\n", "    y_true, y_score = [], []\n", "\n", "    for epoch in range(epochs):\n", "        model.memory.reset_state()\n", "        loss_total = 0\n", "\n", "        for i in range(data.t.size(0)):\n", "            src, dst = data.src[i], data.dst[i]\n", "            t = data.t[i]\n", "            msg = data.msg[i].unsqueeze(0)\n", "\n", "            with torch.no_grad():\n", "                model.update_memory(src.unsqueeze(0), dst.unsqueeze(0), t.unsqueeze(0), msg)\n", "\n", "            pred = model(src.unsqueeze(0), dst.unsqueeze(0))\n", "            label = torch.tensor([1.0])\n", "            loss = F.binary_cross_entropy_with_logits(pred.view(-1), label)\n", "\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()\n", "\n", "            loss_total += loss.item()\n", "            y_true.append(label.item())\n", "            y_score.append(torch.sigmoid(pred).item())\n", "\n", "        print(f\"Epoch {epoch+1}, Loss: {loss_total:.4f}\")\n", "\n", "    # Evaluation\n", "    auc = roc_auc_score(y_true, y_score)\n", "    y_pred_bin = [1 if p > 0.5 else 0 for p in y_score]\n", "    f1 = f1_score(y_true, y_pred_bin)\n", "    fpr, tpr, _ = roc_curve(y_true, y_score)\n", "\n", "    print(f\"TGN ROC-AUC: {auc:.4f}, F1-score: {f1:.4f}\")\n", "\n", "    return fpr, tpr, auc, f1\n", "\n", "# Example:\n"], "metadata": {"id": "sKkASSMi0gji"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# TGAT baseline for temporal graph data\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import roc_auc_score, f1_score, roc_curve\n", "from torch_geometric.data import TemporalData\n", "\n", "# === TGAT Time Encoding ===\n", "class Time2Vec(nn.Module):\n", "    def __init__(self, dim):\n", "        super().__init__()\n", "        self.linear = nn.Linear(1, dim)\n", "        self.freqs = nn.Parameter(torch.randn(dim))\n", "\n", "    def forward(self, t):\n", "        # t: (batch, 1)\n", "        return torch.cat([torch.sin(self.freqs * t), self.linear(t)], dim=-1)\n", "\n", "# === TGAT Simplified Architecture ===\n", "class TGATLinkPredictor(nn.Module):\n", "    def __init__(self, num_nodes, feat_dim, time_dim=8, embed_dim=32):\n", "        super().__init__()\n", "        self.node_embed = nn.Embedding(num_nodes, embed_dim)\n", "        self.time_enc = Time2Vec(time_dim)\n", "        self.fc_msg = nn.Linear(feat_dim + time_dim * 2, embed_dim)\n", "\n", "        self.pred_net = nn.Sequential(\n", "            nn.Linear(embed_dim * 2, embed_dim), nn.ReLU(), nn.Linear(embed_dim, 1)\n", "        )\n", "\n", "    def forward(self, src, dst, t, msg):\n", "        t_input = t.view(1, 1)\n", "        t_feat = self.time_enc(t_input).squeeze(0)  # (dim,)\n", "        feat_src = self.fc_msg(torch.cat([msg, t_feat], dim=-1)) + self.node_embed(src)\n", "        feat_dst = self.fc_msg(torch.cat([msg, t_feat], dim=-1)) + self.node_embed(dst)\n", "        return self.pred_net(torch.cat([feat_src, feat_dst], dim=-1))\n", "\n", "# === Training and Evaluation ===\n", "def train_tgat(data, num_nodes, epochs=10):\n", "    model = TGATLinkPredictor(num_nodes=num_nodes, feat_dim=data.msg.size(-1))\n", "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n", "\n", "    y_true, y_score = [], []\n", "\n", "    for epoch in range(epochs):\n", "        total_loss = 0\n", "\n", "        for i in range(data.t.size(0)):\n", "            src, dst = data.src[i], data.dst[i]\n", "            t = data.t[i].unsqueeze(0)\n", "            msg = data.msg[i]\n", "\n", "            pred = model(src, dst, t, msg)\n", "            label = torch.tensor([1.0])\n", "            loss = F.binary_cross_entropy_with_logits(pred.view(-1), label)\n", "\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()\n", "\n", "            total_loss += loss.item()\n", "            y_true.append(label.item())\n", "            y_score.append(torch.sigmoid(pred).item())\n", "\n", "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n", "\n", "    # Evaluation\n", "    auc = roc_auc_score(y_true, y_score)\n", "    y_pred_bin = [1 if p > 0.5 else 0 for p in y_score]\n", "    f1 = f1_score(y_true, y_pred_bin)\n", "    fpr, tpr, _ = roc_curve(y_true, y_score)\n", "\n", "    print(f\"TGAT ROC-AUC: {auc:.4f}, F1-score: {f1:.4f}\")\n", "\n", "    return fpr, tpr, auc, f1\n", "\n", "# Example:\n"], "metadata": {"id": "CYlDeVkW_qMm"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["# Train models on METRLA dataset\n", "def train_tgn_on_metrla(data, num_nodes, epochs=10):\n", "    model = TGNLinkPredictor(num_nodes=num_nodes, msg_dim=data.msg.size(-1))\n", "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n", "    y_true, y_score = [], []\n", "    for epoch in range(epochs):\n", "        model.memory.reset_state()\n", "        loss_total = 0\n", "        for i in range(data.t.size(0)):\n", "            src, dst = data.src[i], data.dst[i]\n", "            t = data.t[i]\n", "            msg = data.msg[i].unsqueeze(0)\n", "            with torch.no_grad():\n", "                model.update_memory(src.unsqueeze(0), dst.unsqueeze(0), t.unsqueeze(0), msg)\n", "            pred = model(src.unsqueeze(0), dst.unsqueeze(0))\n", "            label = torch.tensor([1.0])\n", "            loss = F.binary_cross_entropy_with_logits(pred.view(-1), label)\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()\n", "            loss_total += loss.item()\n", "            y_true.append(label.item())\n", "            y_score.append(torch.sigmoid(pred).item())\n", "        print(f\"Epoch {epoch+1}, Loss: {loss_total:.4f}\")\n", "    auc = roc_auc_score(y_true, y_score)\n", "    y_pred_bin = [1 if p > 0.5 else 0 for p in y_score]\n", "    f1 = f1_score(y_true, y_pred_bin)\n", "    fpr, tpr, _ = roc_curve(y_true, y_score)\n", "    print(f\"TGN ROC-AUC: {auc:.4f}, F1-score: {f1:.4f}\")\n", "    return fpr, tpr, auc, f1\n", "\n", "def train_tgat_on_metrla(data, num_nodes, epochs=10):\n", "    model = TGATLinkPredictor(num_nodes=num_nodes, feat_dim=data.msg.size(-1))\n", "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n", "    y_true, y_score = [], []\n", "    for epoch in range(epochs):\n", "        total_loss = 0\n", "        for i in range(data.t.size(0)):\n", "            src, dst = data.src[i], data.dst[i]\n", "            t = data.t[i].unsqueeze(0)\n", "            msg = data.msg[i]\n", "            pred = model(src, dst, t, msg)\n", "            label = torch.tensor([1.0])\n", "            loss = F.binary_cross_entropy_with_logits(pred.view(-1), label)\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()\n", "            total_loss += loss.item()\n", "            y_true.append(label.item())\n", "            y_score.append(torch.sigmoid(pred).item())\n", "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n", "    auc = roc_auc_score(y_true, y_score)\n", "    y_pred_bin = [1 if p > 0.5 else 0 for p in y_score]\n", "    f1 = f1_score(y_true, y_pred_bin)\n", "    fpr, tpr, _ = roc_curve(y_true, y_score)\n", "    print(f\"TGAT ROC-AUC: {auc:.4f}, F1-score: {f1:.4f}\")\n", "    return fpr, tpr, auc, f1\n", "\n", "def train_htgn_on_metrla(data, num_nodes):\n", "    return train_htgn(data, num_nodes)\n", "\n", "def run_metrla_experiment():\n", "    data, num_nodes = load_metrla_temporal_data()\n", "    fpr_tgn, tpr_tgn, auc_tgn, _ = train_tgn_on_metrla(data, num_nodes)\n", "    fpr_tgat, tpr_tgat, auc_tgat, _ = train_tgat_on_metrla(data, num_nodes)\n", "    fpr_htgn, tpr_htgn, auc_htgn, _ = train_htgn_on_metrla(data, num_nodes)\n", "    plt.figure(figsize=(8,6))\n", "    plt.plot(fpr_tgn, tpr_tgn, label=f'TGN (AUC = {auc_tgn:.3f})')\n", "    plt.plot(fpr_tgat, tpr_tgat, label=f'TGAT (AUC = {auc_tgat:.3f})')\n", "    plt.plot(fpr_htgn, tpr_htgn, label=f'HTGN (AUC = {auc_htgn:.3f})')\n", "    plt.plot([0,1],[0,1],'k--',lw=1)\n", "    plt.xlabel('False Positive Rate')\n", "    plt.ylabel('True Positive Rate')\n", "    plt.title('ROC Curve Comparison on METRLA')\n", "    plt.legend()\n", "    plt.grid(True)\n", "    plt.tight_layout()\n", "    plt.show()\n", "\n", "run_metrla_experiment()\n"], "metadata": {"id": "metrla_train"}, "execution_count": null, "outputs": []}]}
